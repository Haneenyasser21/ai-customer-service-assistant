import wixData from 'wix-data';
import { OpenAI } from 'openai';
import { getSecret } from 'wix-secrets-backend';
import { cosineSimilarity } from './utils';

export async function processQuery(ownerId, query) {
  try {
    const chunks = await getTopChunks(ownerId, query);

    const instructions = `
      You are a customer service assistant. Answer the user's question based on the provided context.
      Only choose from these emotions (happy,sad, angry, surprised, outofservice).
      Your response should be formatted as follows:
      "Answer: [your answer here]
      Emotion: [emotion here]"
    `;

    const response = await new OpenAI({ apiKey: await getSecret('OPENAI_API_KEY') }).chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [
        { role: 'system', content: instructions },
        { role: 'user', content: `${query}\n\nContext:\n${chunks.join('\n')}` }
      ]
    });

    return response.choices[0].message.content;
  } catch (error) {
    console.error('Error in processQuery:', error);
    throw error;
  }
}

export async function getTopChunks(ownerId, query) {
  const pdfs = await wixData.query('PDFs')
    .eq('ownerId', ownerId)
    .find({ suppressAuth: true });
  const pdfIds = pdfs.items.map(item => item._id);

  const chunks = await wixData.query('KnowledgeChunks')
    .hasSome('pdfId', pdfIds)
    .find();

  const openai = new OpenAI({ apiKey: await getSecret('OPENAI_API_KEY') });
  const embeddingResponse = await openai.embeddings.create({
    model: 'text-embedding-3-small',
    input: query
  });

  const queryEmbedding = embeddingResponse.data[0].embedding;

  let topChunks = chunks.items.map(chunk => {
    const chunkEmbedding = JSON.parse(chunk.embedding);
    return {
      text: chunk.text,
      similarity: cosineSimilarity(queryEmbedding, chunkEmbedding)
    };
  });

  topChunks.sort((a, b) => b.similarity - a.similarity);
  return topChunks.slice(0, 5).map(c => c.text);
}
